Day 7:

Red AI
===

There seem to be many goals for the development of AI, as well as its usage.
Typically, these developments tend to align with the idea that faster, more powerful AI is better.
The first example of this mindset would be that of NVIDIA, which aims to be able to train generative agents with as much computing power as possible.
This type of vision would align with the vision that is called Red AI, where more is better, and the goal is to maximize the accuracy of the AI's output.

But can this be said to always be the case?
Ethical collection of training data, environmental impact of training large models, as well as the impact of the product itself on people are all consequences that may be neglected if we pigeonhole ourselves into the Red AI 'mindset'.
While the cost of training AI increases linearly with the amount of data that the AI is trained on (as well as the number of hyperparameter experiments, and the amount of time it takes to test one example), the accuracy or 'gain' from the AI being trained more diminishes as the training size increases.
So while we must acknowledge the importance and utility provided by the current AI models, it is also important to begin thinking about optimization on all three fronts,
from the amount of time taken to tune the hyperparameters to the amount of time it takes to process a single piece of data.

Again, Red AI is extremely important as it has allowed us to arrive where we are. Nevertheless, we may want to start adopting multiple lenses to view how we approach research and development.


READ:

https://www.virtuousai.com/blog/red-ai-versus-green-ai/

https://medium.com/@ciente/red-ai-vs-green-ai-d7c9e4c6e6af


WILL READ:

https://dl.acm.org/doi/pdf/10.1145/3381831
