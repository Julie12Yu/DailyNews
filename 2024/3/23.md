Day 6:

NVIDIA + Unitree: The H1 humanoid robot!
===

Unitree has collaborated with NVIDIA to help train the H1 robot.
Specifically, at the GTC Conference, the NVIDIA CEO declared that a great route for AI utilization seems to be within robotics,
with the advancement of GPUs leading to an advancement in capabilities of AI robots.
With the progression of GPU computing power, training AI robots with simulations of walking, carrying weights, etc. has become more efficient.
If anything, the progression of GPUs allows for more efficient progression of AI robots, aiding in their ability to 'learn' new movements.
The Unitree H1 robot seems to be powerful and fast, able to hold weight up to 30kg, and potentially being able to reach speeds past 5 m/s.

The Unitree H1 robot has 360 depth perception, pairing LiDAR with a depth camera.
Interestingly enough, while the robot has 'feet' that seem similar to a human foot (a forefoot paired with a heel and ankles), the H1 robot does not have hands!
Instead, stubs with what appears to be textured rubber are present at the end of its forearm.

Along with the H1, the second generation of the Go2 was released (quadruped)!
Besides the improvement in pricing, speed, and mobility, the Go2 includes a LiDAR system as well.

The presence of the LiDAR system seems to be advantageous for a number of reasons.
Firstly, LiDAR scanning seems to have a relatively low minimum detection distance (especially the L1 which Unitree utilizes).
Secondly, LiDAR is able to operate in a number of conditions (regarding lighting).

Point cloud density is effectively the amount of points mapped within a unit area.
The more points present, the better the area is mapped out (more detail!).
As LiDAR systems improve, we will see the point cloud density increase.
