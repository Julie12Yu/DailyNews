Day 8:

K-means Clustering
===

When utilizing k-means clustering, a k number of clusters are generated by the data provided, and each cluster is centered around a centroid (the mean of the data within the cluster).
K-means clustering minimizes the squared Euclidean distance, which calculates the approximate distance (not 100% accurate) between the centroid and the piece of data.
Because k-means looks at squared Euclidean distance, it is fast and can cluster things based on their 'similarity'.
Furthermore, it is good for iterating over all of the data (fast) and is typically utilized with unsupervised machine learning.

It is important to note that k-means makes 2 assumptions.
Firstly, k-means assumes that clusters are of approximately the same size.
Secondly, k-means assumes that the clusters are distributed approximately evenly, so they are spherical.

Thus, should these two conditions not be met, the data should be normalized/standardized.
Common ways may include min-max normalization or mean-SD normalization.

The nearest centroid classifier is when k-means is paired with the 1-nearest neighbor classifier.
New data is put into existing clusters.


WILL READ:

https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html

https://www.sciencedirect.com/science/article/abs/pii/S0020025522014633
