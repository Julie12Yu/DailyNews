Day 9: 

AI Hallucinations
===

Recently, during a meeting at WildLab, a research lab at the University of Washington, a PhD researcher shared her experience with AI speech transcription. When she was using OpenAI's "Whisper" to transcribe the audio during her experiment, she noticed that the AI would hallucinate Youtube/Podcast-esque 'outtros' even when the audio was silent.

This is a common example of AI Hallucination, one of the many phenomenon associated with LLM usage.

Here's a definiton by IBM:
>AI hallucination is a phenomenon wherein a large language model (LLM)—often a generative AI chatbot or computer vision tool—perceives patterns or objects that are nonexistent or imperceptible to human observers, creating outputs that are nonsensical or altogether inaccurate.

Hallucinations seem to be inevitable as AI cannot 'learn' or be trained for every situation that exists. Furthermore, according to IBM:
>overfitting, training data bias/inaccuracy and high model complexity.

It is also important to note that hallucinations are a symptom of a greater issue within LLMs, which is its vulnerability to manipulation and bias. The data you train the AI on will be the way the AI reacts - if you train the LLM on data from 4Chan, the LLM will most likely produce slurs. If you train the LLM on educational articles concerning mathematics, it will (likely) hallucinate when you ask it about pop culture references.

Thus, similar to a mesage from the Mapping VSD onto AI for SGP paper (https://pubmed.ncbi.nlm.nih.gov/34790942/), it is important to repeatedly edit, train, and ensure that the usage of AI is done safely. Technology is akin to the power tools utilized in engineering. They can help our lives a lot, but without the proper safeguards and knowledge of how to use it, more harm may come than good.


READ:

https://www.sify.com/ai-analytics/the-hilarious-and-horrifying-hallucinations-of-ai/

https://www.ibm.com/topics/ai-hallucinations

https://arxiv.org/abs/2401.11817#:~:text=By%20employing%20results%20from%20learning,inevitable%20for%20real%20world%20LLMs.
