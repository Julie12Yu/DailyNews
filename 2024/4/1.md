Day 9: 

AI Hallucinations
===

Recently, during a meeting at WildLab, a research lab at the University of Washington, a PhD researcher shared her experience with AI speech transcription. When she was using OpenAI's "Whisper" to transcribe the audio during her experiment, she noticed that the AI would hallucinate Youtube/Podcast-esque 'outtros' even when the audio was silent.

This is a common example of AI Hallucination, one of the many phenomenon associated with LLM usage.

Here's a definiton by IBM:
>AI hallucination is a phenomenon wherein a large language model (LLM)—often a generative AI chatbot or computer vision tool—perceives patterns or objects that are nonexistent or imperceptible to human observers, creating outputs that are nonsensical or altogether inaccurate.


<img width="711" alt="image" src="https://github.com/Julie12Yu/DailyNews/assets/44332507/0a15cc97-97f3-4f4a-8fc9-6ecce1203cea">


