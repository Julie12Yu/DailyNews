Day 1: 
GTC March 2024
This is my first time doing something like this, so bear with me!

----- Tech Discussion -----
NVIDA is clearly making leaps and bounds with their new tech, increasing the support for AI computation ability by 5 times over the past two years, with the new Blackwell system (consistent of many groups of: two Blackwell chips linked to a Hopper CPU) being able to support trillions of parameters within generative AI. The CEO of NVIDA, Jensen Huang, seems to strongly believe that the future of AI leans strongly towards generative AI, which would be able to greatly decrease the amount of resources necessary to view the desired content. 
A few of the noted features of the new Blackwell system include the RAS engine which does 100% in-system testing, allowing for the maximized runtime of the system, the NVLink which allows for GPUs to work together much more efficiently, as well as Secure AI, which encrypts parameters in transit, during computation, and at rest! Out of the 3, the RAS system seems to be the 'new' addition, while the others may be improvements on previous technology or concepts. 
It seems to be that the focus of NVIDA will be on the progression of efficiency when it comes to generating AI. Bigger, faster GPUs designed to make AI training better. 


----- Ethics Discussion -----
I think it is worth noting that the value that generative AI brings (intellectual value - not just monetary value) needs to be weighed against the environmental and intellectual harms it may bring. 
I understand that NVIDA's GPUs have been used for good - I think I've seen people post about it's use with the prediction of the path of wild fires. However, there is an environmental cost to huge processes of data. Is this generative AI worth it? Or will it bring detriment to the environment and the very people it was supposed to benefit. 
(https://www.scientificamerican.com/article/ais-climate-impact-goes-beyond-its-emissions/) Look there for more
Furthermore, it should be noted that the origin of material that is consumed in the training of AI should be inspected. The intent of many artists and authors may be to help inspire people, or bring people joy. AI inherently copies the art it sees - it does not 'know' and thus cannot 'take inspiration' from things. So is it misuse or abuse of the artists when you take their art and feed it into a machine? 